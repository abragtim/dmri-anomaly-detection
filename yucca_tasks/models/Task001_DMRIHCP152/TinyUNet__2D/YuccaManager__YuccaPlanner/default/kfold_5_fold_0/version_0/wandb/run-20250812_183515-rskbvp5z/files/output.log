WARNING:root:Reusing already computed split file which was split using the kfold method and parameter 5.
INFO:root:Patch size will be infered from hardware constraints
INFO:root:Final batch and patch sizes set to 512 and (128, 96) based on the current constraints.
Max GPU memory usage: 12GB.
Estimated GPU memory usage: 2.5. This includes an offset of 2.5GB to allow a margin of error and account for VRAM grabbed by torch and other backend libraries.
Max patch size: [142, 110]
Max batch size: 512

INFO:root:Using batch size: 512 and patch size: (128, 96)
Composing Transforms
INFO:root:YuccaLightningModule initialized
INFO:root:Deep Supervision Enabled: False
INFO:root:Using 4 workers
INFO:root:Using dataset class: <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTrainDataset'> for train/val and <class 'yucca.modules.data.datasets.YuccaDataset.YuccaTestDataset'> for inference
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/timur/anaconda3/envs/diffusion-segmentation/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:190: .fit(ckpt_path="last") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.
INFO:root:Setting up data for stage: TrainerFn.FITTING
INFO:root:Validating on samples: ['/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/100610', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/101006', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/101915', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/105115', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/106319', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/109830', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/110007', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/110411', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/111009', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/120515', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/128026', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/130821', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/132017', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/135730', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/140319', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/150524', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/153025', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/154330', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/159340', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/160123', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/160931', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/167036', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/175540', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/180937', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/182840', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/185038', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/186040', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/191033', '/Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner/194140']
/Users/timur/anaconda3/envs/diffusion-segmentation/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:658: Checkpoint directory /Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/models/Task001_DMRIHCP152/TinyUNet__2D/YuccaManager__YuccaPlanner/default/kfold_5_fold_0/version_0/checkpoints exists and is not empty.
INFO:root:Loading Model: 2D TinyUNet
INFO:root:
| module                      | #parameters or shape   | #flops     |
|:----------------------------|:-----------------------|:-----------|
| model                       | 7.557K                 | 10.532G    |
|  in_conv                    |  0.204K                |  1.384G    |
|   in_conv.conv1             |   48                   |   0.352G   |
|    in_conv.conv1.conv       |    40                  |    0.226G  |
|    in_conv.conv1.norm       |    8                   |    0.126G  |
|   in_conv.conv2             |   0.156K               |   1.032G   |
|    in_conv.conv2.conv       |    0.148K              |    0.906G  |
|    in_conv.conv2.norm       |    8                   |    0.126G  |
|  encoder_conv1              |  0.912K                |  1.485G    |
|   encoder_conv1.conv1       |   0.312K               |   0.516G   |
|    encoder_conv1.conv1.conv |    0.296K              |    0.453G  |
|    encoder_conv1.conv1.norm |    16                  |    62.915M |
|   encoder_conv1.conv2       |   0.6K                 |   0.969G   |
|    encoder_conv1.conv2.conv |    0.584K              |    0.906G  |
|    encoder_conv1.conv2.norm |    16                  |    62.915M |
|  encoder_conv2              |  3.552K                |  1.422G    |
|   encoder_conv2.conv1       |   1.2K                 |   0.484G   |
|    encoder_conv2.conv1.conv |    1.168K              |    0.453G  |
|    encoder_conv2.conv1.norm |    32                  |    31.457M |
|   encoder_conv2.conv2       |   2.352K               |   0.937G   |
|    encoder_conv2.conv2.conv |    2.32K               |    0.906G  |
|    encoder_conv2.conv2.norm |    32                  |    31.457M |
|  upsample1                  |  0.52K                 |  0.201G    |
|   upsample1.weight          |   (16, 8, 2, 2)        |            |
|   upsample1.bias            |   (8,)                 |            |
|  decoder_conv1              |  1.776K                |  2.844G    |
|   decoder_conv1.conv1       |   1.176K               |   1.875G   |
|    decoder_conv1.conv1.conv |    1.16K               |    1.812G  |
|    decoder_conv1.conv1.norm |    16                  |    62.915M |
|   decoder_conv1.conv2       |   0.6K                 |   0.969G   |
|    decoder_conv1.conv2.conv |    0.584K              |    0.906G  |
|    decoder_conv1.conv2.norm |    16                  |    62.915M |
|  upsample2                  |  0.132K                |  0.201G    |
|   upsample2.weight          |   (8, 4, 2, 2)         |            |
|   upsample2.bias            |   (4,)                 |            |
|  decoder_conv2              |  0.456K                |  2.97G     |
|   decoder_conv2.conv1       |   0.3K                 |   1.938G   |
|    decoder_conv2.conv1.conv |    0.292K              |    1.812G  |
|    decoder_conv2.conv1.norm |    8                   |    0.126G  |
|   decoder_conv2.conv2       |   0.156K               |   1.032G   |
|    decoder_conv2.conv2.conv |    0.148K              |    0.906G  |
|    decoder_conv2.conv2.norm |    8                   |    0.126G  |
|  out_conv                   |  5                     |  25.166M   |
|   out_conv.weight           |   (1, 4, 1, 1)         |            |
|   out_conv.bias             |   (1,)                 |            |

  | Name          | Type             | Params | Mode
-----------------------------------------------------------
0 | train_metrics | MetricCollection | 0      | train
1 | val_metrics   | MetricCollection | 0      | train
2 | model         | TinyUNet         | 7.6 K  | train
3 | loss_fn_train | DiceCE           | 0      | train
4 | loss_fn_val   | DiceCE           | 0      | train
-----------------------------------------------------------
7.6 K     Trainable params
0         Non-trainable params
7.6 K     Total params
0.030     Total estimated model params size (MB)
61        Modules in train mode
0         Modules in eval mode
/Users/timur/anaconda3/envs/diffusion-segmentation/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:369: You have overridden `on_before_batch_transfer` in `LightningModule` but have passed in a `LightningDataModule`. It will use the implementation from `LightningModule` instance.
/Users/timur/anaconda3/envs/diffusion-segmentation/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
INFO:root:Starting training with data from: /Volumes/TimurDKI/dmri_anomaly_detection/yucca_tasks/preprocessed/Task001_DMRIHCP152/YuccaPlanner
2025_08_12_18_36_03 lr-SGD:              0.001
2025_08_12_18_36_03 lr-SGD-momentum:     0.9


2025_08_12_18_38_49 Current Epoch:       1
2025_08_12_18_38_49 Epoch Time:          214.48550081253052
2025_08_12_18_38_49 val/loss:            2.084627389907837
2025_08_12_18_38_49 train/MAE:           1.46932053565979
2025_08_12_18_38_49 train/loss:          -12.468934059143066
2025_08_12_18_38_49 lr-SGD:              0.0009999975326033966
2025_08_12_18_38_49 lr-SGD-momentum:     0.9


2025_08_12_18_41_38 Current Epoch:       2
2025_08_12_18_41_38 Epoch Time:          168.52929306030273
2025_08_12_18_41_38 val/loss:            2.3679165840148926
2025_08_12_18_41_38 train/MAE:           1.4651687145233154
2025_08_12_18_41_38 train/loss:          -10.119319915771484
2025_08_12_18_41_38 lr-SGD:              0.000999990130437938
2025_08_12_18_41_38 lr-SGD-momentum:     0.9


2025_08_12_18_44_24 Current Epoch:       3
2025_08_12_18_44_24 Epoch Time:          165.85611391067505
2025_08_12_18_44_24 val/loss:            1.2193338871002197
2025_08_12_18_44_24 train/MAE:           1.4766448736190796
2025_08_12_18_44_24 train/loss:          -2.644407033920288
2025_08_12_18_44_24 lr-SGD:              0.0009999777935766813
2025_08_12_18_44_24 lr-SGD-momentum:     0.9


2025_08_12_18_47_08 Current Epoch:       4
2025_08_12_18_47_08 Epoch Time:          164.03672194480896
2025_08_12_18_47_08 val/loss:            0.5086485147476196
2025_08_12_18_47_08 train/MAE:           1.4682819843292236
2025_08_12_18_47_08 train/loss:          1.211824893951416
2025_08_12_18_47_08 lr-SGD:              0.000999960522141386
2025_08_12_18_47_08 lr-SGD-momentum:     0.9


2025_08_12_18_49_50 Current Epoch:       5
2025_08_12_18_49_50 Epoch Time:          162.33841824531555
2025_08_12_18_49_50 val/loss:            0.6811433434486389
2025_08_12_18_49_50 train/MAE:           1.4652677774429321
2025_08_12_18_49_50 train/loss:          -2.328009605407715
2025_08_12_18_49_50 lr-SGD:              0.000999938316302514
2025_08_12_18_49_50 lr-SGD-momentum:     0.9


2025_08_12_18_52_35 Current Epoch:       6
2025_08_12_18_52_35 Epoch Time:          165.48203706741333
2025_08_12_18_52_35 val/loss:            1.782364845275879
2025_08_12_18_52_35 train/MAE:           1.4654635190963745
2025_08_12_18_52_35 train/loss:          -4.393466949462891
2025_08_12_18_52_35 lr-SGD:              0.0009999111762792284
2025_08_12_18_52_35 lr-SGD-momentum:     0.9


2025_08_12_18_55_17 Current Epoch:       7
2025_08_12_18_55_17 Epoch Time:          161.8667709827423
2025_08_12_18_55_17 val/loss:            2.107043981552124
2025_08_12_18_55_17 train/MAE:           1.4673479795455933
2025_08_12_18_55_17 train/loss:          -6.046328067779541
2025_08_12_18_55_17 lr-SGD:              0.00099987910233939
2025_08_12_18_55_17 lr-SGD-momentum:     0.9


2025_08_12_18_57_59 Current Epoch:       8
2025_08_12_18_57_59 Epoch Time:          161.4580237865448
2025_08_12_18_57_59 val/loss:            1.3125770092010498
2025_08_12_18_57_59 train/MAE:           1.4718756675720215
2025_08_12_18_57_59 train/loss:          -20.049962997436523
2025_08_12_18_57_59 lr-SGD:              0.0009998420947995553
2025_08_12_18_57_59 lr-SGD-momentum:     0.9
